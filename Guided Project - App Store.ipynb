{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Project 1 - Apps - What ones do we want to make?\n",
    "\n",
    "This project piece is the culmination of of the first section of the Dataquest guided learning.\n",
    "\n",
    "In this scenarion, I am undertaking the role of an analyst working for a company which makes mobile apps for Andriod and IOS Apple devices, to be available on Google Play and the Apple App Store.\n",
    "\n",
    "The apps which are developed are free and revenue comes from in game adds, so the purpose of this analytical piece is to determine which apps are most profitable in the above sense by determining what type of apps attract the most users and therefore the most add revenue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two datasets used:  \n",
    "- Google Play Store Data: https://dq-content.s3.amazonaws.com/350/googleplaystore.csv\n",
    "- Apple Play Store Data: https://dq-content.s3.amazonaws.com/350/AppleStore.csv\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Opening the datasets\n",
    "\n",
    "Both datasets need to be opened, read and transformed into a list of lists.\n",
    "\n",
    "This will be done by:  \n",
    "- importing the `reader` command from the `CSV` module\n",
    "- opening the files which are stored locally to on my computer\n",
    "- stipulating the encoding as `utf8` to aleviate any issues\n",
    "- reading the files\n",
    "- converting the read files into three list variables, one containing the entire dataset, one containing just the headers and one with just the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "# opening the android data #\n",
    "\n",
    "opened = open(r\"C:\\Users\\andre\\OneDrive\\Desktop\\Python Files\\Guided Project - Apps\\googleplaystore.csv\",encoding=\"utf8\")\n",
    "read = reader(opened)\n",
    "android_all_data = list(read)\n",
    "android_headers = android_all_data[0]\n",
    "android_rows = android_all_data[1:]\n",
    "\n",
    "# opening the apple data #\n",
    "\n",
    "opened = open(r\"C:\\Users\\andre\\OneDrive\\Desktop\\Python Files\\Guided Project - Apps\\AppleStore.csv\",encoding=\"utf8\")\n",
    "read = reader(opened)\n",
    "apple_all_data = list(read)\n",
    "apple_headers = apple_all_data[0]\n",
    "apple_rows = apple_all_data[1:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - initial explore of the data\n",
    "\n",
    "To make exploring the data easier in the first instance, we created a function entitled `explore_data()` which takes in 4 arguements:  \n",
    "- `dataset` which is intended to be taken as a list of lists\n",
    "- `start` and `end` which will take the index numbers of the rows we wish to look at\n",
    "- `rows_columns` which will take a boolean value and be defaulted to `False`\n",
    "\n",
    "This function will enable us to easily view a select few rows of the input datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows:  10842\n",
      "Number of columns:  13\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def explore_data(dataset, start, end, rows_columns = False):\n",
    "    for row in dataset[start:end]:\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "        \n",
    "    if rows_columns:\n",
    "        print('Number of rows: ', len(dataset))\n",
    "        print('Number of columns: ', len(dataset[0]))\n",
    "        \n",
    "print(explore_data(android_all_data, 0, 3, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above we have run the `explore_data` function for first 3 rows for the `android_all_data` data set which does contain the headers/column titles; so the output is the column titles and the first 3 rows of data.\n",
    "\n",
    "We have also stipulated ` rows_columns` to be `True` so the output also included a count of the rows and columns in the android_all_data dataset. We can see that in total, the dataset contains data for 10,841 apps (note the first row of this dataset is the headers) and 13 columns.\n",
    "\n",
    "At a quick glance, the columns which could be of use at a later date are:  \n",
    "- `App`\n",
    "- `Category`\n",
    "- `Rating`\n",
    "- `Reviews`\n",
    "- `Installs`\n",
    "- `Type`\n",
    "- `Price`\n",
    "- `Genres`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have already defined the function `explore_data()` in the section above we do not need to repeat our actions to initially explore the Apple App Store dataset, we simply need to call the fucntion and change the `dataset` parameter to one of the 3 apple lists we created in Step 1.  \n",
    "  \n",
    "For the below I will again use the list containing the entirety of the dataset including headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows:  7198\n",
      "Number of columns:  16\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(explore_data(apple_all_data, 0, 3, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Apple App dataset contains information on 7,197 apps (again `row[0]` contains the headers) and holds 16 columns, 3 more than the Google Play dataset.  \n",
    "  \n",
    "  The columns which could be of use appear to be:  \n",
    "  - `track_name`\n",
    "  -` price`\n",
    "  - `rating_count_tot`\n",
    "  - `rating_count_ver`\n",
    "  - `user_rating`\n",
    "  - `prime_genre`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Deleting Incomplete Data - Google Play Store  \n",
    "  \n",
    "In this article (https://www.kaggle.com/lava18/google-play-store-apps/discussion/66015) about the google play dataset, it is mentioned that there is a missing `rating` for entry `[10,472]` and a column shift has occured as a result.\n",
    "\n",
    "Whilst the end result of this section will be to simply remove said row from our dataset using the command `del android_all_data[10472]`, for the purposes of this exercise I am going to pretend that we do not know where this error has occured and need to undertake steps to check all of our rows have the correct amount of data points (13).  \n",
    "  \n",
    "I will do this by comparing the number of columns held in the `android_headers` list to the number of entries each row has in the `android_all_data` list of lists.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index number:  10473\n",
      "\n",
      "\n",
      "row length:  12\n",
      "\n",
      "\n",
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n"
     ]
    }
   ],
   "source": [
    "for row in android_all_data[1:]:       \n",
    "    if len(row) != len(android_headers):\n",
    "     \n",
    "        print('index number: ', android_all_data.index(row))\n",
    "        print('\\n')\n",
    "        print('row length: ', len(row))\n",
    "        print('\\n')\n",
    "        print(row)\n",
    "       \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a point of note, the index number returned from the above is 1 greater than the index number being discussed in the link above. Reading the discussion further it seems that the parties involved in the discussion were working on a version of the dataset with the headers removed whereas I was working on the full version which accounts for the discrepancy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of thoroughness and again assuming we haven't been given the answer via a public forum, we should run the above check for the Apple dataset as well.  \n",
    "  \n",
    "  I will again be running the check on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in apple_all_data[1:]:       \n",
    "    if len(row) != len(apple_headers):\n",
    "     \n",
    "        print('index number: ', apple_all_data.index(row))\n",
    "        print('\\n')\n",
    "        print('row length: ', len(row))\n",
    "        print('\\n')\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above code returns no values, therefore confirming that from the perspecitve of this checking method the Apple dataset is 100% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to remove the corrupt data point from the Google Play data set and will be done by running the code below.\n",
    "\n",
    "Note, I have turned the below code into a note after I ran it to prevent me from inadvertently running it in the future and removing other complete rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del android_all_data[10473]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10841\n"
     ]
    }
   ],
   "source": [
    "print(len(android_all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All being well, if we rerun the checks for the google dataset we should be met with a nil return thereby indicating that the corrupt row has been removed and the rest of the dataset is as we need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in android_all_data[1:]:       \n",
    "    if len(row) != len(android_headers):\n",
    "     \n",
    "        print('index number: ', android_all_data.index(row))\n",
    "        print('\\n')\n",
    "        print('row length: ', len(row))\n",
    "        print('\\n')\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As hoped, the above has returned nothing so we are in a good position to proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Removing Duplicates from the data  \n",
    "  \n",
    "As with any new dataset part of the initial cleansing process should be to identify and subsiquently remove any and all duplicate entries; so we shall be doing this for both of our datasets by using the Name of the apps in the datasets as our unique identifiers.  \n",
    "  \n",
    "  ### Identifying the duplicates  \n",
    "  To identify the duplicates from the Google Play Store dataset, we will use a series of lists entitled `unique` and `duplicate` and itterate over the full dataset to idenfity what, if any, apps names appear more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates:  1181\n",
      "\n",
      "\n",
      "Duplicate examples:\n",
      "Quick PDF Scanner + OCR FREE\n",
      "Box\n",
      "Google My Business\n",
      "ZOOM Cloud Meetings\n",
      "join.me - Simple Meetings\n",
      "Box\n",
      "Zenefits\n",
      "Google Ads\n",
      "Google My Business\n",
      "Slack\n",
      "FreshBooks Classic\n",
      "Insightly CRM\n",
      "QuickBooks Accounting: Invoicing & Expenses\n",
      "HipChat - Chat Built for Teams\n",
      "Xero Accounting Software\n"
     ]
    }
   ],
   "source": [
    "duplicate_apps = []\n",
    "unique_apps = []\n",
    "\n",
    "for row in android_all_data[1:]:\n",
    "    if row[0] in unique_apps:    #we know from previous steps that the first column (index 0) of the goolge data contains the apps name\n",
    "        duplicate_apps.append(row[0])\n",
    "    else:\n",
    "        unique_apps.append(row[0])\n",
    "        \n",
    "print('Number of duplicates: ', len(duplicate_apps))\n",
    "print('\\n')\n",
    "print('Duplicate examples:')\n",
    "for i in duplicate_apps[:15]:\n",
    "    print(i)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the duplicates\n",
    "\n",
    "We can now see what within the full google play store dataset 1181 entries are duplicates and action needs to be taken to remove them. However before we remove them we need to assertain what the deletion criteria is to be to avoid erroneously deleting datapoints.  \n",
    "  \n",
    "Lets start by looking at all of the entries for one of the duplicated apps, namely `Instagram`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "\n",
      "\n",
      "['Instagram', 'SOCIAL', '4.5', '66577446', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "\n",
      "\n",
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "\n",
      "\n",
      "['Instagram', 'SOCIAL', '4.5', '66509917', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(android_headers)\n",
    "for row in android_all_data[1:]:\n",
    "    if row[0] == 'Instagram':\n",
    "        print(row)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the exception of the number of reviews reveived (column 4/ index 3) all the information for the duplicate apps appears to be the same so we will be focusing on using the number of reviews each app has received to remove our duplicates.  \n",
    "  \n",
    "Logic dictates that the datapoint with the highest number of reviews is the one we want to keep and work with so the code below will work on that premis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Length:  9659\n",
      "Actual Length:  9659\n"
     ]
    }
   ],
   "source": [
    "max_reviews = {}\n",
    "\n",
    "for row in android_all_data[1:]:\n",
    "    if (row[0] in max_reviews) and (float(row[3]) < max_reviews[row[0]]):\n",
    "        max_reviews[row[0]] = float(row[3])\n",
    "        \n",
    "    elif row[0] not in max_reviews:\n",
    "        max_reviews[row[0]] = float(row[3])\n",
    "        \n",
    "print('Expected Length: ', len(android_all_data) - 1 - len(duplicate_apps))\n",
    "print('Actual Length: ', len(max_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values printed above confrims that the expected length of our soon to be de-duplicated dataset matches the actual length of the list of apps once the duplicates have been removed.  \n",
    "  \n",
    "We will now use our `max_reviews` dictionary to assist in removing the duplicated rows from our primary dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_cleaned = []\n",
    "android_added = []\n",
    "\n",
    "for row in android_all_data[1:]:\n",
    "    if float(row[3]) == max_reviews[row[0]] and row[0] not in android_added:\n",
    "        android_cleaned.append(row)\n",
    "        android_added.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite – FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "\n",
      "['Pixel Draw - Number Art Coloring Book', 'ART_AND_DESIGN', '4.3', '967', '2.8M', '100,000+', 'Free', '0', 'Everyone', 'Art & Design;Creativity', 'June 20, 2018', '1.1', '4.4 and up']\n",
      "\n",
      "\n",
      "Number of rows:  9659\n",
      "Number of columns:  13\n"
     ]
    }
   ],
   "source": [
    "explore_data(android_cleaned, 0, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows in our new cleaned dataset matches that of our `max_reviews` dictionary and our expected length, happy days!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick check of the Apple Store data will show that there are no duplicates so the above steps do not need to be repeated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates:  0\n",
      "\n",
      "\n",
      "Duplicate examples:\n"
     ]
    }
   ],
   "source": [
    "unique_apps = []\n",
    "duplicate_apps = []\n",
    "\n",
    "for row in apple_all_data[1:]:\n",
    "    if row[0] in unique_apps:\n",
    "        duplicate_apps.append(row[0])\n",
    "    else:\n",
    "        unique_apps.append(row[0])\n",
    "        \n",
    "print('Number of duplicates: ', len(duplicate_apps))\n",
    "print('\\n')\n",
    "print('Duplicate examples:')\n",
    "for i in duplicate_apps[:15]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Removing Non English apps\n",
    "  \n",
    "Given the universality of both app stores and the fact that we are undertaking this whole project for a company which works in English and only makes apps for English speaking customers, we need to again explore our data to idetify and subsiquently remove any apps which appear to not be for an English speaking audience as we do not want to include them in our analysis to follow.  \n",
    "  \n",
    "Using the American Standard Code for Information Interchange (ASCII) as the base of our work, it is known that the charachters commonly used in written English possess an `ord()` number between 0 and 127 so we will use this fact to build a function to check the names of our apps to identify if any non English characters are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to build a function that checks a single sting input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def is_english(string):\n",
    "    for c in string:\n",
    "        if ord(c) > 127:\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "print(is_english('视剧视剧'))\n",
    "print(is_english('hello'))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst the above function works as desired, certain characters, such as smilies, have an `ord()` value which falls outside the conventional 0 to 127 range so amendments need to be made to not automatically rule out an english app title with a small amount of characters outside the range.  \n",
    "  \n",
    "  For the purposes of this exercise I have decided that an app title can have upto a maximum of 3 non standard characters before it is excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def is_english(string):\n",
    "    ascii_count = 0\n",
    "    \n",
    "    for c in string:\n",
    "        if ord(c) > 127:\n",
    "            ascii_count += 1\n",
    "            \n",
    "    if ascii_count >3:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "print(is_english('视剧视剧'))\n",
    "print(is_english('hello 😜'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a function built with an acceptable tollerance limit for non english characters, we can use this to filter out the non english apps from both datasets, creating two new datasets as we go.\n",
    "\n",
    "When looking through the Google Play we need to ensure we are using the newly created `android_cleaned` list from the previous section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows:  9614\n",
      "Number of columns:  13\n",
      "None\n",
      "Non-english Android Apps remove:  45\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows:  6183\n",
      "Number of columns:  16\n",
      "None\n",
      "Non-english Apple Apps remove:  0\n"
     ]
    }
   ],
   "source": [
    "android_eng = []\n",
    "android_non_eng_rem = 0\n",
    "apple_eng = []\n",
    "apple_non_eng_rem = 0\n",
    "\n",
    "for row in android_cleaned:\n",
    "    if is_english(str(row[0])):\n",
    "        android_eng.append(row)\n",
    "    elif is_english(str(row[0])) is False:\n",
    "        android_non_eng_rem += 1\n",
    "    \n",
    "for row in apple_rows:\n",
    "    if is_english(str(row[1])):\n",
    "        apple_eng.append(row)\n",
    "    elif is_english(str(row[0])) is False:\n",
    "        apple_non_eng_rem += 1\n",
    "        \n",
    "print(explore_data(android_eng,0,2, True))\n",
    "print('Non-english Android Apps remove: ', android_non_eng_rem)\n",
    "print('\\n')\n",
    "print(explore_data(apple_eng,0,2,True))\n",
    "print('Non-english Apple Apps remove: ', apple_non_eng_rem)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Isolating free apps  \n",
    "The final cleansing exercise we will undertake for this project is to isolate only the free apps from our previously cleansed dataset, as we are working for a developer who only builds free to instal apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "android_final length:  8862\n",
      "apple_final length:  3222\n"
     ]
    }
   ],
   "source": [
    "android_final = []\n",
    "apple_final = []\n",
    "\n",
    "for row in android_eng:\n",
    "    if row[7] == '0':\n",
    "        android_final.append(row)\n",
    "        \n",
    "for row in apple_eng:\n",
    "    if row[4] == '0.0':\n",
    "        apple_final.append(row)\n",
    "        \n",
    "  \n",
    "        \n",
    "print('android_final length: ', len(android_final))\n",
    "print('apple_final length: ', len(apple_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Finding the most common apps by genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of ease and so save us continuously having to refer to the early sections of this project, I will run the explore function to return the headers and 2 rows of data for both of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(android_headers)\n",
    "print('\\n')\n",
    "print(explore_data(android_final, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(apple_headers)\n",
    "print('\\n')\n",
    "print(explore_data(apple_final, 0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need to build a function to populate a frequency table and to then sort said table in decending order. \n",
    "We will build the frequency tables to show the characteristics of the given column as a percentage instead of an absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games :  58.16 %\n",
      "Entertainment :  7.88 %\n",
      "Photo & Video :  4.97 %\n",
      "Education :  3.66 %\n",
      "Social Networking :  3.29 %\n",
      "Shopping :  2.61 %\n",
      "Utilities :  2.51 %\n",
      "Sports :  2.14 %\n",
      "Music :  2.05 %\n",
      "Health & Fitness :  2.02 %\n",
      "Productivity :  1.74 %\n",
      "Lifestyle :  1.58 %\n",
      "News :  1.33 %\n",
      "Travel :  1.24 %\n",
      "Finance :  1.12 %\n",
      "Weather :  0.87 %\n",
      "Food & Drink :  0.81 %\n",
      "Reference :  0.56 %\n",
      "Business :  0.53 %\n",
      "Book :  0.43 %\n",
      "Navigation :  0.19 %\n",
      "Medical :  0.19 %\n",
      "Catalogs :  0.12 %\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def freq_table(dataset, index):\n",
    "    new_table = {}\n",
    "    total = 0\n",
    "    \n",
    "    for row in dataset:\n",
    "        total += 1\n",
    "        if row[index] in new_table:\n",
    "            new_table[row[index]] += 1\n",
    "        else:\n",
    "            new_table[row[index]] = 1\n",
    "            \n",
    "    table_perc = {}\n",
    "    \n",
    "    for key in new_table:\n",
    "        percentage = round(((new_table[key] / total) * 100), 2)\n",
    "        table_perc[key] = percentage\n",
    "        \n",
    "    table_to_display = []\n",
    "    \n",
    "    for key in table_perc:\n",
    "        table_to_display.append((table_perc[key],key))\n",
    "        \n",
    "    table_sorted = sorted(table_to_display, reverse = True)\n",
    "    \n",
    "    for e in table_sorted:\n",
    "        print(e[1], ': ', e[0], '%')\n",
    "\n",
    "print(freq_table(apple_final, -5))\n",
    "\n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table2(dataset, index):\n",
    "    new_table = {}\n",
    "    total = 0\n",
    "    \n",
    "    for row in dataset:\n",
    "        total += 1\n",
    "        if row[index] in new_table:\n",
    "            new_table[row[index]] += 1\n",
    "        else:\n",
    "            new_table[row[index]] = 1\n",
    "            \n",
    "    table_perc = {}\n",
    "    \n",
    "    for key in new_table:\n",
    "        percentage = round(((new_table[key] / total) * 100), 2)\n",
    "        table_perc[key] = percentage\n",
    "        \n",
    "    return table_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that for the Apple Store dataset over half the apps are Games (58.16%) with the next most popular genre being that of Entertainment (7.88%).  \n",
    "\n",
    "For the Google Play Store dataset there are two columns which we want to explore:  \n",
    "- `Catagories`\n",
    "- `Genres`\n",
    "\n",
    "Lets look at `catagory` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAMILY :  18.79 %\n",
      "GAME :  9.64 %\n",
      "TOOLS :  8.44 %\n",
      "BUSINESS :  4.58 %\n",
      "LIFESTYLE :  3.9 %\n",
      "PRODUCTIVITY :  3.89 %\n",
      "FINANCE :  3.7 %\n",
      "MEDICAL :  3.53 %\n",
      "SPORTS :  3.42 %\n",
      "PERSONALIZATION :  3.32 %\n",
      "COMMUNICATION :  3.25 %\n",
      "HEALTH_AND_FITNESS :  3.07 %\n",
      "PHOTOGRAPHY :  2.95 %\n",
      "NEWS_AND_MAGAZINES :  2.8 %\n",
      "SOCIAL :  2.66 %\n",
      "TRAVEL_AND_LOCAL :  2.34 %\n",
      "SHOPPING :  2.25 %\n",
      "BOOKS_AND_REFERENCE :  2.14 %\n",
      "DATING :  1.86 %\n",
      "VIDEO_PLAYERS :  1.78 %\n",
      "MAPS_AND_NAVIGATION :  1.4 %\n",
      "EDUCATION :  1.25 %\n",
      "FOOD_AND_DRINK :  1.24 %\n",
      "ENTERTAINMENT :  1.04 %\n",
      "LIBRARIES_AND_DEMO :  0.94 %\n",
      "AUTO_AND_VEHICLES :  0.93 %\n",
      "HOUSE_AND_HOME :  0.84 %\n",
      "WEATHER :  0.8 %\n",
      "EVENTS :  0.71 %\n",
      "ART_AND_DESIGN :  0.68 %\n",
      "PARENTING :  0.65 %\n",
      "COMICS :  0.62 %\n",
      "BEAUTY :  0.6 %\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(freq_table(android_final,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversly, the spread of the catagories in the google store is much closer than that of the Apple Store. The most common catagory here is that of `Family` which makes up 18.79% of the dataset with `Game` coming in second at 9.64%.  \n",
    "  \n",
    "And now to look at the `Genre` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools :  8.43 %\n",
      "Entertainment :  6.07 %\n",
      "Education :  5.35 %\n",
      "Business :  4.58 %\n",
      "Productivity :  3.89 %\n",
      "Lifestyle :  3.89 %\n",
      "Finance :  3.7 %\n",
      "Medical :  3.53 %\n",
      "Sports :  3.46 %\n",
      "Personalization :  3.32 %\n",
      "Communication :  3.25 %\n",
      "Action :  3.1 %\n",
      "Health & Fitness :  3.07 %\n",
      "Photography :  2.95 %\n",
      "News & Magazines :  2.8 %\n",
      "Social :  2.66 %\n",
      "Travel & Local :  2.32 %\n",
      "Shopping :  2.25 %\n",
      "Books & Reference :  2.14 %\n",
      "Simulation :  2.04 %\n",
      "Dating :  1.86 %\n",
      "Arcade :  1.86 %\n",
      "Video Players & Editors :  1.78 %\n",
      "Casual :  1.75 %\n",
      "Maps & Navigation :  1.4 %\n",
      "Food & Drink :  1.24 %\n",
      "Puzzle :  1.13 %\n",
      "Racing :  0.99 %\n",
      "Role Playing :  0.94 %\n",
      "Libraries & Demo :  0.94 %\n",
      "Auto & Vehicles :  0.93 %\n",
      "Strategy :  0.91 %\n",
      "House & Home :  0.84 %\n",
      "Weather :  0.8 %\n",
      "Events :  0.71 %\n",
      "Adventure :  0.68 %\n",
      "Comics :  0.61 %\n",
      "Beauty :  0.6 %\n",
      "Art & Design :  0.6 %\n",
      "Parenting :  0.5 %\n",
      "Card :  0.44 %\n",
      "Casino :  0.43 %\n",
      "Trivia :  0.42 %\n",
      "Educational;Education :  0.39 %\n",
      "Educational :  0.37 %\n",
      "Board :  0.37 %\n",
      "Education;Education :  0.34 %\n",
      "Word :  0.26 %\n",
      "Casual;Pretend Play :  0.24 %\n",
      "Music :  0.2 %\n",
      "Racing;Action & Adventure :  0.17 %\n",
      "Puzzle;Brain Games :  0.17 %\n",
      "Entertainment;Music & Video :  0.17 %\n",
      "Casual;Brain Games :  0.14 %\n",
      "Casual;Action & Adventure :  0.14 %\n",
      "Arcade;Action & Adventure :  0.12 %\n",
      "Action;Action & Adventure :  0.1 %\n",
      "Educational;Pretend Play :  0.09 %\n",
      "Board;Brain Games :  0.09 %\n",
      "Simulation;Action & Adventure :  0.08 %\n",
      "Parenting;Education :  0.08 %\n",
      "Entertainment;Brain Games :  0.08 %\n",
      "Parenting;Music & Video :  0.07 %\n",
      "Educational;Brain Games :  0.07 %\n",
      "Casual;Creativity :  0.07 %\n",
      "Art & Design;Creativity :  0.07 %\n",
      "Education;Pretend Play :  0.06 %\n",
      "Role Playing;Pretend Play :  0.05 %\n",
      "Education;Creativity :  0.05 %\n",
      "Role Playing;Action & Adventure :  0.03 %\n",
      "Puzzle;Action & Adventure :  0.03 %\n",
      "Entertainment;Creativity :  0.03 %\n",
      "Entertainment;Action & Adventure :  0.03 %\n",
      "Educational;Creativity :  0.03 %\n",
      "Educational;Action & Adventure :  0.03 %\n",
      "Education;Music & Video :  0.03 %\n",
      "Education;Brain Games :  0.03 %\n",
      "Education;Action & Adventure :  0.03 %\n",
      "Adventure;Action & Adventure :  0.03 %\n",
      "Video Players & Editors;Music & Video :  0.02 %\n",
      "Sports;Action & Adventure :  0.02 %\n",
      "Simulation;Pretend Play :  0.02 %\n",
      "Puzzle;Creativity :  0.02 %\n",
      "Music;Music & Video :  0.02 %\n",
      "Entertainment;Pretend Play :  0.02 %\n",
      "Casual;Education :  0.02 %\n",
      "Board;Action & Adventure :  0.02 %\n",
      "Trivia;Education :  0.01 %\n",
      "Travel & Local;Action & Adventure :  0.01 %\n",
      "Tools;Education :  0.01 %\n",
      "Strategy;Education :  0.01 %\n",
      "Strategy;Creativity :  0.01 %\n",
      "Strategy;Action & Adventure :  0.01 %\n",
      "Simulation;Education :  0.01 %\n",
      "Role Playing;Brain Games :  0.01 %\n",
      "Racing;Pretend Play :  0.01 %\n",
      "Puzzle;Education :  0.01 %\n",
      "Parenting;Brain Games :  0.01 %\n",
      "Music & Audio;Music & Video :  0.01 %\n",
      "Lifestyle;Pretend Play :  0.01 %\n",
      "Lifestyle;Education :  0.01 %\n",
      "Health & Fitness;Education :  0.01 %\n",
      "Health & Fitness;Action & Adventure :  0.01 %\n",
      "Entertainment;Education :  0.01 %\n",
      "Communication;Creativity :  0.01 %\n",
      "Comics;Creativity :  0.01 %\n",
      "Casual;Music & Video :  0.01 %\n",
      "Card;Brain Games :  0.01 %\n",
      "Card;Action & Adventure :  0.01 %\n",
      "Books & Reference;Education :  0.01 %\n",
      "Art & Design;Pretend Play :  0.01 %\n",
      "Art & Design;Action & Adventure :  0.01 %\n",
      "Arcade;Pretend Play :  0.01 %\n",
      "Adventure;Education :  0.01 %\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(freq_table(android_final,-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst the difference between the `catagory` and `genres` fields aren't immediately clear, it is apparant that `genres` is much more granular than `catagory` as it has significantly more unique values.  \n",
    "  \n",
    "Given this exercise is a high level one, we shall use `catagory` going forward.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 - Finding the average number of installs by genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just because the Apple App Store is dominated by `Game`, this doesn't necisarrily mean that this is the most popular catagory for the users. To explore this premice further we will try and calculate the average number of installs per catagory.  \n",
    "  \n",
    "  Whilst the Apple App Store data set does not contain a datapoint for th enumber of installs, we can use the number of ratings received as an alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social Networking : 71548.35\n",
      "Photo & Video : 28441.54\n",
      "Games : 22788.67\n",
      "Music : 57326.53\n",
      "Reference : 74942.11\n",
      "Health & Fitness : 23298.02\n",
      "Weather : 52279.89\n",
      "Utilities : 18684.46\n",
      "Travel : 28243.8\n",
      "Shopping : 26919.69\n",
      "News : 21248.02\n",
      "Navigation : 86090.33\n",
      "Lifestyle : 16485.76\n",
      "Entertainment : 14029.83\n",
      "Food & Drink : 33333.92\n",
      "Sports : 23008.9\n",
      "Book : 39758.5\n",
      "Finance : 31467.94\n",
      "Education : 7003.98\n",
      "Productivity : 21028.41\n",
      "Business : 7491.12\n",
      "Catalogs : 4004.0\n",
      "Medical : 612.0\n"
     ]
    }
   ],
   "source": [
    "genres_apple = freq_table2(apple_final,-5)\n",
    "\n",
    "for genre in genres_apple:\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    \n",
    "    for row in apple_final:\n",
    "        genre_row = row[-5]\n",
    "        if genre_row == genre:\n",
    "            total += float(row[5])\n",
    "            len_genre += 1\n",
    "            \n",
    "    average_number_ratings = round(total / len_genre, 2)\n",
    "    \n",
    "    print(genre, \":\", average_number_ratings)   \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At face value `Navigation` apps hold the highest number of average reviews. However, when using a mean average calculation as we did above they are susceptible to being skewed.  \n",
    "  \n",
    "As evidenced below, in the Apple Store dataset there are a total of 6 naviagtion apps and 4 of those have less than 15,000 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waze - GPS Navigation, Maps & Real-time Traffic : 345046\n",
      "Google Maps - Navigation & Transit : 154911\n",
      "Geocaching® : 12811\n",
      "CoPilot GPS – Car Navigation & Offline Maps : 3582\n",
      "ImmobilienScout24: Real Estate Search in Germany : 187\n",
      "Railway Route Search : 5\n"
     ]
    }
   ],
   "source": [
    "for app in apple_final:\n",
    "    if app[-5] == \"Navigation\":\n",
    "        print(app[1], \":\", app[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Full disclosure, I am losing steam a tad with the full write up part of this project, mainly as it is taking up too much time.**\n",
    "  \n",
    "**From here on in I will just be doing the coding part of the guided project as I am keen to move on to the intermediate intro to Python course.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,000,000+ :  15.75 %\n",
      "100,000+ :  11.55 %\n",
      "10,000,000+ :  10.51 %\n",
      "10,000+ :  10.22 %\n",
      "1,000+ :  8.41 %\n",
      "100+ :  6.92 %\n",
      "5,000,000+ :  6.82 %\n",
      "500,000+ :  5.57 %\n",
      "50,000+ :  4.77 %\n",
      "5,000+ :  4.51 %\n",
      "10+ :  3.54 %\n",
      "500+ :  3.25 %\n",
      "50,000,000+ :  2.28 %\n",
      "100,000,000+ :  2.12 %\n",
      "50+ :  1.92 %\n",
      "5+ :  0.79 %\n",
      "1+ :  0.51 %\n",
      "500,000,000+ :  0.27 %\n",
      "1,000,000,000+ :  0.23 %\n",
      "0+ :  0.05 %\n",
      "0 :  0.01 %\n"
     ]
    }
   ],
   "source": [
    "freq_table(android_final,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratings have been rounded, catagorised and include a + and , symbol which will need to be removed to enable us to calculate the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ART_AND_DESIGN : 1905351.67\n",
      "AUTO_AND_VEHICLES : 647317.82\n",
      "BEAUTY : 513151.89\n",
      "BOOKS_AND_REFERENCE : 8767811.89\n",
      "BUSINESS : 1704192.34\n",
      "COMICS : 817657.27\n",
      "COMMUNICATION : 38326063.2\n",
      "DATING : 854028.83\n",
      "EDUCATION : 3057207.21\n",
      "ENTERTAINMENT : 19428913.04\n",
      "EVENTS : 253542.22\n",
      "FINANCE : 1387692.48\n",
      "FOOD_AND_DRINK : 1924897.74\n",
      "HEALTH_AND_FITNESS : 4167457.36\n",
      "HOUSE_AND_HOME : 1313681.91\n",
      "LIBRARIES_AND_DEMO : 638503.73\n",
      "LIFESTYLE : 1437816.27\n",
      "GAME : 13006872.89\n",
      "FAMILY : 4371709.12\n",
      "MEDICAL : 107167.23\n",
      "SOCIAL : 23253652.13\n",
      "SHOPPING : 7036877.31\n",
      "PHOTOGRAPHY : 17805627.64\n",
      "SPORTS : 4274688.72\n",
      "TRAVEL_AND_LOCAL : 13984077.71\n",
      "TOOLS : 10695245.29\n",
      "PERSONALIZATION : 5201482.61\n",
      "PRODUCTIVITY : 16772838.59\n",
      "PARENTING : 542603.62\n",
      "WEATHER : 5074486.2\n",
      "VIDEO_PLAYERS : 24790074.18\n",
      "NEWS_AND_MAGAZINES : 9549178.47\n",
      "MAPS_AND_NAVIGATION : 4056941.77\n"
     ]
    }
   ],
   "source": [
    "catagories_android = freq_table2(android_final,1)\n",
    "\n",
    "for cat in catagories_android:\n",
    "    total = 0\n",
    "    len_catagory = 0\n",
    "    \n",
    "    for app in android_final:\n",
    "        catagory_app = app[1]\n",
    "        if catagory_app == cat:\n",
    "            number_installs = app[5]\n",
    "            number_installs = number_installs.replace('+', '')\n",
    "            number_installs = number_installs.replace(',', '')\n",
    "            total += float(number_installs)\n",
    "            len_catagory += 1\n",
    "\n",
    "    average_installs = round(total / len_catagory, 2)\n",
    "    print(cat, ':', average_installs)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
